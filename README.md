# Teacher-Guided-Reinforcement-Learning

## 📖 项目背景
本项目目标是进行关于强化学习 (Reinforcement Learning)的实验，特别是 Q-learning 与 SARSA算法的比较，以及探索在教师-学生框架 (Interactive Reinforcement Learning, IntRL)下的学习效率提升效果。

环境为 **11×11 的静态网格世界 (Grid World)**，其中：
- 代理 (agent) 从随机起点出发，目标是到达终点 `(10,10)`。
- 途中有两类固定障碍物：**L 型** 和 **十字型**。
- 每一步都会获得奖励或惩罚：
  - 到达目标：`+25`
  - 撞上障碍：`-10`
  - 每移动一步：`-1`
<img width="1273" height="769" alt="image" src="https://github.com/user-attachments/assets/788382f8-1ea9-4e01-913f-14110a6c948e" />

---

## 🎯 实现内容
项目共分为四个任务：

### **Task 1: Q-learning**
- 实现 Q-learning 算法并训练智能体。
- 使用 **ε-greedy 策略** 平衡探索与利用。
- 输出：
  - 每回合奖励曲线图（含移动平均）
  - 指标：平均奖励、成功率、平均学习速度
  - 训练好的 Q-table（作为教师使用）

### **Task 2: SARSA**
- 实现 SARSA 算法并训练智能体。
- 使用与 Task 1 相同的超参数，保证公平对比。
- 输出：
  - 奖励曲线图
  - 指标：平均奖励、成功率、平均学习速度
  - 训练好的 Q-table（作为教师使用）

### **Task 3: Q-learning 教师指导**
- 使用 **已训练好的 Q-learning 智能体** 作为教师，指导新的 Q-learning 学生。
- 教师提供建议的机制：
  - **可用性 (Availability)**：教师在某一步提供建议的概率。
  - **准确性 (Accuracy)**：教师建议正确的概率。
- 参数组合：
  - Availability ∈ `[0.1, 0.3, 0.5, 0.7, 1.0]`
  - Accuracy ∈ `[0.1, 0.3, 0.5, 0.7, 1.0]`
  - 共 **25 种配置**。
- 输出：
  - 不同配置下的指标（平均奖励、成功率、平均学习速度）
  - 热力图（横轴为可用性，纵轴为准确性，颜色表示平均奖励）

### **Task 4: SARSA 教师指导**
- 与 Task 3 类似，但使用 **SARSA 教师和学生**。
- 输出与 Task 3 相同，用于对比 **Q-learning 教师** 与 **SARSA 教师** 的效果。

---

## ⚙️ 方法与参数设置
所有任务需使用**相同的超参数**以保证公平比较：

- **学习率 (α):** 0.1 – 0.5  
- **折扣因子 (γ):** 0.9 – 0.99  
- **ε (探索率):**  
  - 衰减策略：初始 0.8 – 1.0，最终 0.01 – 0.1  
  - 固定策略：0.1 – 0.3  
- **训练回合数 (Episodes):** 300 – 1000  
- **单回合最大步数:** 50 – 100  

教师实验 (Task 3 & 4) 可使用较少回合数以节省计算。

---

## 📊 成果与评估
项目输出以下成果：

1. **训练过程曲线图**
   - 奖励随回合的变化（包含原始数据与移动平均线）
   - 成功率曲线
   - Q-learning 与 SARSA 的对比图

2. **教师指导实验结果**
   - 不同可用性/准确性组合下的性能指标
   - 热力图展示平均奖励

3. **分析与讨论**
   - Q-learning 与 SARSA 的基准性能比较
   - 教师对学习曲线的影响
   - Q-learning 与 SARSA 在教师指导下的效果差异
   - 总结哪种算法更受益于教师指导

---


## 🚀 项目资源
- `env.py` – Grid World 环境实现  
- `Environment Guide.pdf` – 环境说明文档  
- `images/` – 可视化素材（智能体、目标、障碍物）  

---




✨ 通过该项目，你将深入理解 **Q-learning 与 SARSA 的差异**，以及 **教师指导 (IntRL)** 如何影响强化学习的收敛效率与效果。
